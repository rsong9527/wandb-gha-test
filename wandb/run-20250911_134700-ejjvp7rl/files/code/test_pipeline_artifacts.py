#!/usr/bin/env python3
"""
æ¨¡æ‹ŸWoven pipelineè¾“å‡ºçš„W&B artifactæµ‹è¯•
ä¸“é—¨å¤ç°pipelineè¾“å‡ºartifactsä¸¢å¤±çš„é—®é¢˜
"""

import os
import sys
import time
import wandb
import tempfile
import json
from pathlib import Path

def create_pipeline_outputs():
    """åˆ›å»ºæ¨¡æ‹Ÿçš„pipelineè¾“å‡ºæ–‡ä»¶"""
    temp_dir = Path(tempfile.mkdtemp(prefix="pipeline_outputs_"))
    
    # 1. åˆ›å»º.pbæ–‡ä»¶ï¼ˆprotobufæ¨¡å‹æ–‡ä»¶ï¼‰
    pb_file = temp_dir / "model_v1.pb"
    with open(pb_file, 'wb') as f:
        # æ¨¡æ‹ŸäºŒè¿›åˆ¶protobufæ•°æ®
        fake_pb_data = b'\x08\x96\x01\x12\x04\x08\x01\x10\x01' * 1000  # æ¨¡æ‹Ÿprotobufæ ¼å¼
        f.write(fake_pb_data)
    
    # 2. åˆ›å»ºå¤§çš„.pbæ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿ25MB+çš„æ–‡ä»¶ï¼‰
    large_pb_file = temp_dir / "large_model.pb"
    with open(large_pb_file, 'wb') as f:
        # åˆ›å»ºçº¦5MBçš„æ–‡ä»¶ï¼ˆé¿å…å¤ªå¤§å½±å“æµ‹è¯•é€Ÿåº¦ï¼‰
        chunk = b'\x08\x96\x01\x12\x04\x08\x01\x10\x01' * 10000
        for _ in range(50):  # 50 * 100KB â‰ˆ 5MB
            f.write(chunk)
    
    # 3. åˆ›å»ºé…ç½®æ–‡ä»¶
    config_file = temp_dir / "pipeline_config.json"
    config_data = {
        "model_version": "v1.15.0",
        "pipeline_type": "demo_day_2023_few_s1",
        "created_at": time.time(),
        "triton_client": True,
        "inference_config": {
            "batch_size": 32,
            "max_sequence_length": 512
        }
    }
    with open(config_file, 'w') as f:
        json.dump(config_data, f, indent=2)
    
    # 4. åˆ›å»ºè¯„ä¼°ç»“æœæ–‡ä»¶
    results_file = temp_dir / "evaluation_results.txt"
    with open(results_file, 'w') as f:
        f.write("MTMC Evaluation Results\n")
        f.write("======================\n")
        f.write("HOTA: 65.63\n")
        f.write("DetA: 68.05\n")
        f.write("AssA: 63.423\n")
        f.write("DetRe: 83.573\n")
        f.write("DetPr: 74.746\n")
        f.write("AssRe: 65.567\n")
        f.write("AssPr: 91.818\n")
        f.write("LocA: 89.072\n")
        f.write("OWTA: 72.796\n")
        f.write("HOTA(0): 74.894\n")
        f.write("LocA(0): 87.491\n")
    
    # 5. åˆ›å»ºå¤šä¸ªè¾“å‡ºæ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿå¤æ‚pipelineï¼‰
    outputs_dir = temp_dir / "outputs"
    outputs_dir.mkdir()
    
    for i in range(5):
        output_file = outputs_dir / f"output_{i:03d}.pb"
        with open(output_file, 'wb') as f:
            f.write(b'\x08\x96\x01\x12\x04\x08\x01\x10\x01' * (100 * (i + 1)))
    
    return temp_dir, [pb_file, large_pb_file, config_file, results_file] + list(outputs_dir.glob("*.pb"))

def main():
    print("=== Pipeline Artifacts æµ‹è¯• ===")
    
    # æ£€æŸ¥ç¯å¢ƒ
    api_key = os.getenv('WANDB_API_KEY')
    base_url = os.getenv('WANDB_BASE_URL', 'https://api.wandb.ai')
    is_ci = os.getenv('CI', 'false').lower() == 'true'
    is_gha = os.getenv('GITHUB_ACTIONS', 'false').lower() == 'true'
    
    print(f"ğŸ”‘ API Key: {'è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
    print(f"ğŸŒ Base URL: {base_url}")
    print(f"ğŸ—ï¸ CIç¯å¢ƒ: {'æ˜¯' if is_ci else 'å¦'}")
    print(f"ğŸ™ GitHub Actions: {'æ˜¯' if is_gha else 'å¦'}")
    print(f"ğŸ Pythonç‰ˆæœ¬: {sys.version}")
    print(f"ğŸ“¦ W&Bç‰ˆæœ¬: {wandb.__version__}")
    
    if not api_key:
        print("âŒ é”™è¯¯: WANDB_API_KEY æœªè®¾ç½®")
        return False
    
    try:
        # åˆå§‹åŒ–W&B - æ¨¡æ‹Ÿpipelineè¿è¡Œ
        print("\n--- åˆå§‹åŒ–Pipelineè¿è¡Œ ---")
        run = wandb.init(
            project="pipeline-artifact-test",
            name=f"{'gha' if is_gha else 'local'}-pipeline-{int(time.time())}",
            tags=["pipeline-test", "artifact-debug", "demo_day_2023_few_s1"],
            config={
                "model_version": "v1.15.0",
                "pipeline_type": "demo_day_2023_few_s1",
                "environment": "gha" if is_gha else "local"
            }
        )
        print(f"âœ… Pipelineè¿è¡Œåˆå§‹åŒ–: {run.name}")
        print(f"âœ… é¡¹ç›®: {run.project}")
        print(f"âœ… URL: {run.url}")
        
        # è®°å½•pipelineæŒ‡æ ‡
        print("\n--- è®°å½•PipelineæŒ‡æ ‡ ---")
        wandb.log({
            "pipeline_stage": "preprocessing",
            "processed_files": 1250,
            "processing_time": 45.2
        })
        wandb.log({
            "pipeline_stage": "inference", 
            "batch_size": 32,
            "inference_time": 120.5
        })
        wandb.log({
            "pipeline_stage": "evaluation",
            "mtmc_hota": 65.63,
            "mtmc_deta": 68.05,
            "mtmc_assa": 63.423
        })
        print("âœ… PipelineæŒ‡æ ‡è®°å½•å®Œæˆ")
        
        # åˆ›å»ºpipelineè¾“å‡ºæ–‡ä»¶
        print("\n--- åˆ›å»ºPipelineè¾“å‡º ---")
        temp_dir, pipeline_files = create_pipeline_outputs()
        
        total_size = sum(f.stat().st_size for f in pipeline_files)
        print(f"âœ… åˆ›å»ºäº† {len(pipeline_files)} ä¸ªpipelineæ–‡ä»¶")
        print(f"âœ… æ€»å¤§å°: {total_size / (1024*1024):.1f} MB")
        
        for file in pipeline_files:
            size_mb = file.stat().st_size / (1024*1024)
            print(f"  ğŸ“„ {file.name}: {size_mb:.1f} MB")
        
        # åˆ›å»ºpipelineè¾“å‡ºartifact - è¿™æ˜¯å…³é”®æµ‹è¯•ç‚¹
        print("\n--- åˆ›å»ºPipelineè¾“å‡ºArtifact ---")
        pipeline_artifact = wandb.Artifact(
            name="outputs-demo_day_2023_few_s1",  # ä½¿ç”¨Wovençš„å‘½åæ ¼å¼
            type="pipeline_output",  # ä½¿ç”¨pipelineç±»å‹
            description="Pipelineè¾“å‡ºæ–‡ä»¶ - æ¨¡æ‹ŸWovençš„demo_day_2023_few_s1"
        )
        
        # æ·»åŠ æ‰€æœ‰pipelineæ–‡ä»¶
        for file in pipeline_files:
            pipeline_artifact.add_file(str(file))
            print(f"âœ… æ·»åŠ pipelineæ–‡ä»¶: {file.name}")
        
        # ä¸Šä¼ pipeline artifact - å…³é”®æµ‹è¯•ç‚¹
        print("\n--- ä¸Šä¼ Pipeline Artifact ---")
        print("ğŸ”„ å¼€å§‹ä¸Šä¼ pipelineè¾“å‡º...")
        logged_artifact = wandb.log_artifact(pipeline_artifact)
        print("âœ… log_artifact() è°ƒç”¨å®Œæˆ")
        
        # ç­‰å¾…ä¸Šä¼ å®Œæˆ
        print("ğŸ”„ ç­‰å¾…pipeline artifactä¸Šä¼ å®Œæˆ...")
        logged_artifact.wait()
        print(f"âœ… Pipeline Artifactä¸Šä¼ å®Œæˆ: {logged_artifact.name}:{logged_artifact.version}")
        
        # é¢å¤–ç­‰å¾…æ—¶é—´ï¼ˆæ¨¡æ‹ŸWovençš„30ç§’ç­‰å¾…ï¼‰
        print("\n--- Pipelineå¤„ç†ç­‰å¾…æ—¶é—´ ---")
        print("ğŸ”„ ç­‰å¾…30ç§’ç¡®ä¿pipelineåå°å¤„ç†å®Œæˆ...")
        time.sleep(30)
        
        # é€šè¿‡APIéªŒè¯pipeline artifact
        print("\n--- éªŒè¯Pipeline Artifact ---")
        try:
            api = wandb.Api()
            retrieved_artifact = api.artifact(f"{run.entity}/{run.project}/outputs-demo_day_2023_few_s1:latest")
            print(f"âœ… APIéªŒè¯æˆåŠŸ: {retrieved_artifact.name}")
            print(f"âœ… æ–‡ä»¶æ•°é‡: {len(retrieved_artifact.files())}")
            
            total_size = 0
            for file in retrieved_artifact.files():
                total_size += file.size
                print(f"  ğŸ“„ {file.name} ({file.size / (1024*1024):.1f} MB)")
            
            print(f"âœ… æ€»å¤§å°: {total_size / (1024*1024):.1f} MB")
                
        except Exception as e:
            print(f"âŒ Pipeline Artifact APIéªŒè¯å¤±è´¥: {e}")
            print("ğŸš¨ è¿™å¯èƒ½å°±æ˜¯Wovené‡åˆ°çš„é—®é¢˜ï¼")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import shutil
        shutil.rmtree(temp_dir)
        
        # å®Œæˆè¿è¡Œ
        wandb.finish()
        print("\nâœ… Pipelineæµ‹è¯•å®Œæˆ")
        
        print(f"\nğŸ”— è¯·æ£€æŸ¥W&B Dashboard: {run.url}")
        print("ğŸ“‹ é‡ç‚¹æ£€æŸ¥:")
        print("  1. è¿è¡Œæ˜¯å¦å‡ºç°åœ¨é¡¹ç›®åˆ—è¡¨ä¸­")
        print("  2. Pipelineè¾“å‡ºArtifactæ˜¯å¦åœ¨Artifactsé¡µé¢å¯è§")
        print("  3. æ‰€æœ‰.pbæ–‡ä»¶æ˜¯å¦éƒ½åœ¨artifactä¸­")
        print("  4. å¤§æ–‡ä»¶æ˜¯å¦æ­£ç¡®ä¸Šä¼ ")
        print("  5. å¯¹æ¯”stagingç¯å¢ƒå’ŒWovenç¯å¢ƒçš„å·®å¼‚")
        
        return True
        
    except Exception as e:
        print(f"âŒ Pipelineæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
